#coding=utf-8

## 池化层/汇聚层（Pooling Layer）：
    # 通常，在连续的卷积层之间会周期性地插入一个汇聚层。
    # 它的作用是逐渐降低数据体的空间尺寸，这样的话就能减少网络中参数的数量，使得计算资源耗费变少，也就能有效控制过拟合。
    # 汇聚层使用MAX操作，对输入数据体的每一个深度切片独立进行操作，改变它的空间尺寸。
    # 最常见的形式是汇聚层使用尺寸2x2的滤波器，以步长为2对每个深度切片进行降采样，将其中75%的激活信息都丢掉。
    # 每个MAX操作是从4个数字中取最大值（也就是在深度切片中某个2x2的区域）。
    # 深度保持不变。

## 汇聚层的一些公式：

    # 输入数据体尺寸W1⋅H1⋅D1
    # 有两个超参数：
    #
    # 空间大小F
    # 步长S
    # 输出数据体尺寸W2⋅H2⋅D2 ,其中
    # W2=（W1−F）/S+1
    # H2=（H1−F）/S+1
    # D2=D1
    # 因为对输入进行的是固定函数计算，所以mei有引入参数
    #
    # 在汇聚层中很少使用零填充

## 在实践中，最大汇聚层通常只有两种形式：
    # 一种是F=3，S=2，也叫重叠汇聚（overlapping pooling），
    # 另一个更常用的是F=2,S=2。对更大感受进行汇聚尺寸也更大，而且往往对网络有破坏性。

## 普通汇聚（General Pooling）：
    # 除了最大汇聚，汇聚单元还可以使用其他的函数，比如平均汇聚（average pooling）或者范式汇聚（L2-norm pooling）。
    # 平均汇聚历史上比较常用，但是现在很少使用了，因为实践证明，最大汇聚的效果比平均汇聚要好。
    # 汇聚层在输入数据体的每个深度切片上，独立地对其进行空间上的降采样。
    # 左边：本例中，输入数据体尺寸[224x224x64]被降采样到了[112x112x64]，采用的滤波器尺寸是2，步长为2，而深度不变。
    # 右边：最常用的降采样操作是取最大值，也就是最大汇聚，这里步长为2，每个取最大值操作是从4个数字中选取（即2x2的方块区域中）。

## 池化或汇聚（pooling）
    # 1、tf.nn.avg_pool:平均池化
    # 2、tf.nn.max_pool:最大池化

## tf.nn.max_pool(value, ksize, strides, padding, data_format='NHWC', name=None)

## 参数是四个，和卷积很类似：
    # 第一个参数value：需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch, height, width, channels]这样的shape
    # 第二个参数ksize：池化窗口的大小，取一个四维向量，一般是[1, height, width, 1]，因为我们不想在batch和channels上做池化，所以这两个维度设为了1
    # 第三个参数strides：和卷积类似，窗口在每一个维度上滑动的步长，一般也是[1, stride,stride, 1]
    # 第四个参数padding：和卷积类似，可以取’VALID’ 或者’SAME’，大多数时候都是“VALID”
    # 第五个参数data_format:张量的数据格式，可以是“NHWC” 或“NCHW”，一般就是默认，必须要和conv2d一致。
    # 第六个参数name：给池化节点起一个名字